# Solid Octo Palm Tree: Wikia之图分析

[Github 项目](https://github.com/kawa-yoiko/solid-octo-palm-tree)

本项目实现了对Wikia站点节点的爬取与分析，完成了图结构上的相关计算与可视化。

站点爬取与可视化由*吕时清(2018013379)*完成。

图论算法的实现与优化、并行化由*周知谦(2018013380)*完成。

性能分析报告见本文档最后一节。

### 编译

目前可以在 macOS 上编译。其他平台上应也能编译，但需要与图形库 raylib 链接，暂时没有完成适配。并行版本在G++-8上测试过。

进入 `src/painter/`，执行：

```sh
./compile.sh
```


## 打开方式

包中含有 macOS 的可执行程序。从控制台进入 `bin/` 目录，执行 `./octo` 即可运行。

可以通过控制台参数指定使用的数据集，例如 `./octo undertale` 即使用 Undertale 数据集。

![](res/1.png)

图中的顶点可以用鼠标拖曳并重新排列。拖曳空白部分可以平移视图，鼠标滚轮用于缩放。

右侧面板的「Epigraph bias」即前述参数 $k$，调整参数时，图的颜色会实时更新。下方可选择显示不同数据，包含下述的全部算法，用顶点颜色表示在图上。其中单源最短路（SSSP）只有拖曳顶点时才会显示。

### 切换数据集

我们爬取了 Cave Story 与 Undertale 两个游戏 Wiki 的数据集，位于 `src/crawler/` 目录下，分别命名为 `cavestory-processed.txt` 与 `undertale-processed.txt`。

另外，也可以用 `src/crawler/` 中的 JavaScript 程序可以爬取其他的子站。作为例子，安装 Node.js 后，在该目录下执行：

```sh
node crawl.js nichijou
node process.js nichijou
```

即可获得文件 `nichijou-processed.txt`，对应子站 nichijou.fandom.com（动漫《日常》）的数据集。将其移动到 `octo` 同一目录下，执行 `./octo nichijou` 即可。


## 建模

通过 MediaWiki API 爬取 Wikia 子站的文章内容，提取其中的链接建立带边权的有向图，并通过这张图探究整个子站文章的组织结构，同时也能找出较为主要的文章。

具体来说，为每一篇文章（包括重定向页面和 Wiki 附件页面）建立一个顶点。若某文章的首段（目录之前的这部分简介性文字）共有 $a$ 个链接，后续段落共有 $b$ 个链接，则为每个首段链接建立一条权值为 $\frac k {ka + b}$ 的边，为每个后续段链接建立一条权值为 $\frac 1 {ka + b}$ 的边指向对应页面，其中 $k > 0$ 是一个可调的参数。这样一来，一个顶点出发的边权之和固定为 $1$，可以很好地刻画「从一个页面出发的转移概率」；参数 $k$ 代表对首段的重视程度，即点击任一个首段链接的概率均为后续段中链接的 $k$ 倍。$k = 1$ 时首段与后续段同等重要，一般有 $k > 1$。

在计算最短路时，所有的边权均取倒数，即新的边权代表「从一个页面反复出发，至到达该页面一次为止的期望总出发次数」。从顶点 $u$ 到顶点 $v$ 之间的最短路越短，代表从 $u$ 页面出发越容易到达 $v$ 页面。


## 算法实现

以下图论算法的复杂度中，简记 $n=|V|,\ m=|E|$

### 最短路 Shortest path

定义：从一点到另一点边权和最小的路径。

尝试使用了：

算法一：Floyd-Warshall 算法 复杂度（多源最短路）：$O(n^3)$

算法二：堆优化的Dijkstra算法 复杂度（单源最短路）：$O(m \log n)$

最终使用算法二

### 介数中心度 Betweenness centrality

定义：其余点对间经过该点的最短路与最短路数量比之和。

即介数中心度越高，该点越可能出现在其他点对间最短路上。

尝试使用了：

算法一：预处理点对间最短路长度和数量，枚举点对。复杂度：$O(n^3)$

算法二：带权图的Brandes算法。复杂度：$O(nm\log n)$

### 紧密中心度 Closeness centrality

定义：图中一点的紧密中心度为到所有点的最短路的倒数之和。

即介数中心度越高，该点距离其他所有点越近。

按定义枚举计算，复杂度：$O(nm\log n)$

### 强连通分量 Strongly connected component

定义：图的强连通分量为极大的内部点对间均可互相到达的子图。

使用Tarjan算法计算。复杂度：$O(n+m)$

### 网页排名 PageRank

定义：在图上随机游走，停留于各点的概率。

由于质量更高的网页更容易被引用，该指标一定程度上衡量了网页的质量。

迭代传递排名。复杂度：$O(km)$ ，其中 $k$ 为迭代次数，一般取10~20即可收敛。

### 最短路

使用堆优化的Dijkstra算法

复杂度（单源最短路）：$O(m \log n)$

## 性能分析与优化

本项目运行的效率瓶颈在于最短路与中心度的计算，项目最初使用的Floyd-Warshell算法与betweenness计算复杂度均为$O(n^3)$，随后更改为在稀疏图上更有效的带二项堆优化的Dijkstra算法与Brandes算法，时间复杂度均为$O(m \log n)$。最终版本针对预计算最短路信息的存储进行了优化，并将DIjkstra替换为SPFA，进一步压缩了运行时间。

![profiler result](res/profile.png)

如图，使用Time profiler可以确认占用时间最长的是中心度计算和最短路计算，此外应还有被编译inline的closeness计算。针对这三个算法，使用openmp进行并行化。由于稀疏图上存在访问存储的瓶颈，最终在八线程的机器上取得了约三倍的效率。相比于串行优化前，可用的图规模提升了近两个数量级。